{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ine-divider](https://user-images.githubusercontent.com/7065401/92672068-398e8080-f2ee-11ea-82d6-ad53f7feb5c0.png)\n",
    "<hr>\n",
    "\n",
    "### MySQL and MariaDB for Python Developers\n",
    "# Interacting with Python versus MySQL data types\n",
    "\n",
    "In this project, you will explore the interfaces between Python data types and MySQL data types.\n",
    "\n",
    "You will need access to a MySQL installation where you have superuser permissions. If you do not have such access elsewhere, installing to your personal workstation is a good idea.  Alternately, you might wish to use a Docker container for a self-contained installation.  See ` https://hub.docker.com/_/mysql` for details on that option.\n",
    "\n",
    "![orange-divider](https://user-images.githubusercontent.com/7065401/92672455-187a5f80-f2ef-11ea-890c-40be9474f7b7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "**Dynamically guessing good schema**\n",
    "\n",
    "Python variables and attributes are dynamically typed, but each individual value has a strict type.  We sometimes are presented with collections of Python collections, and would like to determine good data layout for this data in MySQL automatically.\n",
    "\n",
    "For this task, assume that your Python data is in the form of an iterable of namedtuples.  After analyzing data input, your function should product a MySQL SQL statement to create a proposed table.  Obviously, emphasizing that this inference is a guess is important, since future Pyton data produced in the same application may not be compatible with the schema. In use, the function should operate in a manner similar to the below:\n",
    "\n",
    "```python\n",
    ">>> print(infer_schema(list_of_named_tuples))\n",
    "CREATE TABLE my_records (\n",
    "    a SMALLINT, \n",
    "    b BIGINT DEFAULT NULL,\n",
    "    c DECIMAL(40,25),\n",
    "    d REAL DEFAULT NULL,\n",
    "    e TEXT\n",
    ");\n",
    "```\n",
    "\n",
    "At the least, the proposed schema should be compatible with the data actually encountered.  If you decide it is not possible to unify the data in a single data definition, you should raise an appropriate exception.  Several sample datasets are provided for you to test against.  You should expand these for more robust testing, especially to consider additional edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Numbers1(a=1.23, b=Decimal('1.15573'), c=1000000000000, d=2, e=Fraction(22, 7)),\n",
       " Numbers1(a=4.56, b=Decimal('1.155727349790921717935726'), c=-22, d=5, e=Fraction(1, 3)),\n",
       " Numbers1(a=7.89, b=Decimal('1.0'), c=56, d=9, e=Fraction(5, 1))]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from samples import data1, data2, data3, data4, data5, data6\n",
    "# For example...\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/92672455-187a5f80-f2ef-11ea-890c-40be9474f7b7.png)\n",
    "\n",
    "## Part 2\n",
    "\n",
    "**Working with other Python collections**\n",
    "\n",
    "No solution is provided here, but you should be able to re-use most of the work with namedtuples.  Consider how you would need to change the table inference if you are given an iterable of dictionaries? What about an iterable of data classes? What about an iterable of plain lists or tuples. What about and iterable of custom Python objects with various attributes.\n",
    "\n",
    "What would be reasonable exception checking if you wished to use a iterable of heterogeneous Python \"data objects\"? In some ways, it might be reasonable to consider a namedtuple data class, or dictionary \"morally equivalent\" from the point-of-view of a PostgreSQL table.  What limits are likely to apply.\n",
    "\n",
    "The solution provided to part 1 did not consider NULLable columns. It might be reasonable to look for Python `None` values in the data set and use that as guidance for being NULLable.  Moreover, if dictionaries or other mappings are the source data, it *might* (or might not) be appropriate to treat a missing key as a NULL value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![orange-divider](https://user-images.githubusercontent.com/7065401/92672455-187a5f80-f2ef-11ea-890c-40be9474f7b7.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
